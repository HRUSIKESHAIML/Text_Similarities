{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13483997249264842\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'How many total number of pizza slices are eaten by Avelina?'.split()\n",
    "l2 = 'I like pepporoni pizza scices'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13363062095621217\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "def get_cosine(vec1, vec2):\n",
    "    common = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in common])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()]) \n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()]) \n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "   \n",
    "    if not denominator:\n",
    "        return 0.0 \n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text): \n",
    "    words = text.split() \n",
    "    return Counter(words)\n",
    "\n",
    "text1 = 'How much speed is the car going at?' \n",
    "text2 = 'wanted to buy a sedan car soon'\n",
    "\n",
    "vector1 = text_to_vector(text1) \n",
    "vector2 = text_to_vector(text2) \n",
    "cosine = get_cosine(vector1, vector2)\n",
    "print(cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13363062095621217\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'How much speed is the car going at?'.split()\n",
    "l2 = 'wanted to buy a sedan car soon'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'how much speed the car is going at'.split()\n",
    "l2 = 'I like to play football'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6172133998483676\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'did you like to play foot ball'.split()\n",
    "l2 = 'i like to play volly ball'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857142\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'did you like to play foot ball'.split()\n",
    "l2 = 'yes, i like to play foot ball'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6396021490668313\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'the answer is 30 , its 30 ,30 slices'.split()\n",
    "l2 = '30 slices'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22360679774997896\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'how old are you'.split()\n",
    "l2 = 'i am 30 years old'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarities are better than other matching similarities algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "def levenshtein(s1,s2): \n",
    "    if len(s1) > len(s2):\n",
    "        s1,s2 = s2,s1 \n",
    "    distances = range(len(s1) + 1) \n",
    "    for index2,char2 in enumerate(s2):\n",
    "        newDistances = [index2+1]\n",
    "        for index1,char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1]) \n",
    "            else:\n",
    "                 newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1]))) \n",
    "        distances = newDistances \n",
    "    return distances[-1]\n",
    "\n",
    "print(levenshtein(\"How many total number of pizza slices are eaten by Avelina?\",\"I like pepporoni pizza slices\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "def levenshtein(s1,s2): \n",
    "    if len(s1) > len(s2):\n",
    "        s1,s2 = s2,s1 \n",
    "    distances = range(len(s1) + 1) \n",
    "    for index2,char2 in enumerate(s2):\n",
    "        newDistances = [index2+1]\n",
    "        for index1,char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1]) \n",
    "            else:\n",
    "                 newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1]))) \n",
    "        distances = newDistances \n",
    "    return distances[-1]\n",
    "\n",
    "print(levenshtein(\"How much speed is the car going at?\",\"I wanted to buy a sedan car soon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "def levenshtein(s1,s2): \n",
    "    if len(s1) > len(s2):\n",
    "        s1,s2 = s2,s1 \n",
    "    distances = range(len(s1) + 1) \n",
    "    for index2,char2 in enumerate(s2):\n",
    "        newDistances = [index2+1]\n",
    "        for index1,char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1]) \n",
    "            else:\n",
    "                 newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1]))) \n",
    "        distances = newDistances \n",
    "    return distances[-1]\n",
    "\n",
    "print(levenshtein(\"How much speed is the car going at?\",\"I like to play football\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "def levenshtein(s1,s2): \n",
    "    if len(s1) > len(s2):\n",
    "        s1,s2 = s2,s1 \n",
    "    distances = range(len(s1) + 1) \n",
    "    for index2,char2 in enumerate(s2):\n",
    "        newDistances = [index2+1]\n",
    "        for index1,char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1]) \n",
    "            else:\n",
    "                 newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1]))) \n",
    "        distances = newDistances \n",
    "    return distances[-1]\n",
    "\n",
    "print(levenshtein(\"did you like to play football\",\"I like to play volly ball\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "levenshtein scores are changeing based on number of words are present in the sentence. so its difficlt us to define a threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def build_vector(iterable1, iterable2):\n",
    "    counter1 = Counter(iterable1)\n",
    "    counter2 = Counter(iterable2)\n",
    "    all_items = set(counter1.keys()).union(set(counter2.keys()))\n",
    "    vector1 = [counter1[k] for k in all_items]\n",
    "    vector2 = [counter2[k] for k in all_items]\n",
    "    return vector1, vector2\n",
    "\n",
    "def cosim(v1, v2):\n",
    "    dot_product = sum(n1 * n2 for n1, n2 in zip(v1, v2) )\n",
    "    magnitude1 = math.sqrt(sum(n ** 2 for n in v1))\n",
    "    magnitude2 = math.sqrt(sum(n ** 2 for n in v2))\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "l1 = 'How old are you'.split()\n",
    "l2 = 'what is your age'.split()\n",
    "\n",
    "\n",
    "v1, v2 = build_vector(l1, l2)\n",
    "print(cosim(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity:  0.4082482904638631\n"
     ]
    }
   ],
   "source": [
    "# Program to measure the similarity between  \n",
    "# two sentences using cosine similarity. \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "# X = input(\"Enter first string: \").lower() \n",
    "# Y = input(\"Enter second string: \").lower() \n",
    "X =\"How old are you?\"\n",
    "Y =\"what is your age?\"\n",
    "  \n",
    "# tokenization \n",
    "X_list = word_tokenize(X)  \n",
    "Y_list = word_tokenize(Y) \n",
    "  \n",
    "# sw contains the list of stopwords \n",
    "sw = stopwords.words('english')  \n",
    "l1 =[];l2 =[] \n",
    "  \n",
    "# remove stop words from the string \n",
    "X_set = {w for w in X_list if not w in sw}  \n",
    "Y_set = {w for w in Y_list if not w in sw} \n",
    "  \n",
    "# form a set containing keywords of both strings  \n",
    "rvector = X_set.union(Y_set)  \n",
    "for w in rvector: \n",
    "    if w in X_set: l1.append(1) # create a vector \n",
    "    else: l1.append(0) \n",
    "    if w in Y_set: l2.append(1) \n",
    "    else: l2.append(0) \n",
    "c = 0\n",
    "  \n",
    "# cosine formula  \n",
    "for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i] \n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "print(\"similarity: \", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 =\"How old are you?\"\n",
    "doc_2 =\"what is your age?\"\n",
    "\n",
    "def Jaccard_Similarity(doc1, doc2): \n",
    "    \n",
    "    words_doc1 = set(doc1.lower().split()) \n",
    "    words_doc2 = set(doc2.lower().split())\n",
    "    \n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "    union = words_doc1.union(words_doc2)\n",
    "        \n",
    "    return float(len(intersection)) / len(union)\n",
    "Jaccard_Similarity(doc_1,doc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:  How old are you?\n",
      "Sentence 2:  what is your age?\n",
      "Similarity index value :  0.55\n",
      "Not Similar\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from itertools import product\n",
    "import numpy\n",
    "\n",
    "#str1 = \"How much speed is the car going at? \"\n",
    "#str2 = \"Wanted to buy a sedan soon.\"\n",
    "\n",
    "#str1 = \"How many total number of pizza slices are eaten by Avelina? \"\n",
    "#str2 = \"I like pepporoni pizza\"\n",
    "\n",
    "\n",
    "str1 = \"How old are you?\"\n",
    "str2 = \"what is your age?\"\n",
    "\n",
    "#str1 = \"how old are you.\"\n",
    "#str2 = \"what's your age.\"\n",
    "\n",
    "#str1 = \"Cat is drinking water.\"\n",
    "#str2 = \"Lions eat flesh.\"\n",
    "\n",
    "#str1 = \"He loves to play football.\"\n",
    "#str2 = \"Football is his favourite sport.\"\n",
    "\n",
    "# str1 = \"Many consider Maradona as the best player in soccer history.\"\n",
    "# str2 = \"Maradona is one of the best soccer player.\"\n",
    "\n",
    "# str1 = \"I was given a card by her in the garden.\"\n",
    "# str2 = \"In the garden, she gave me a card.\"\n",
    "\n",
    "# str1 = \"Ballmer has been vocal in the past warning that Linux is a threat to Microsoft.\"\n",
    "# str2 = \"In the memo, Ballmer reiterated the open-source threat to Microsoft.\"\n",
    "# str1 = \"The boy is fetching water from the well.\"\n",
    "# str2 = \"The lion is running in the forest.\"\n",
    "# str1 = \"A school is a place where kids go to study.\"\n",
    "# str2 = \"School is an institution for children who want to study.\"\n",
    "# str1 = \"The world knows it has lost a heroic champion of justice and freedom.\"\n",
    "# str2 = \"The earth recognizes the loss of a valiant champion of independence and justice.\"\n",
    "# str1 = \"A cemetery is a place where dead people's bodies or their ashes are buried.\"\n",
    "# str2 = \"A graveyard is an area of land ,sometimes near a church, where dead people are buried.\" \n",
    "\n",
    "##---------------Defining stopwords for English Language---------------##\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "##---------------Initialising Lists---------------##\n",
    "filtered_sentence1 = []\n",
    "filtered_sentence2 = []\n",
    "lemm_sentence1 = []\n",
    "lemm_sentence2 = []\n",
    "sims = []\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "simi = []\n",
    "final = []\n",
    "same_sent1 = []\n",
    "same_sent2 = []\n",
    "#ps = PorterStemmer()\n",
    "\n",
    "##---------------Defining WordNet Lematizer for English Language---------------##\n",
    "lemmatizer  =  WordNetLemmatizer()\n",
    "\n",
    "##---------------Tokenizing and removing the Stopwords---------------##\n",
    "\n",
    "for words1 in word_tokenize(str1):\n",
    "    if words1 not in stop_words:\n",
    "        if words1.isalnum():\n",
    "            filtered_sentence1.append(words1)\n",
    "\n",
    "##---------------Lemmatizing: Root Words---------------##\n",
    "\n",
    "for i in filtered_sentence1:\n",
    "    lemm_sentence1.append(lemmatizer.lemmatize(i))\n",
    "    \n",
    "#print(lemm_sentence1)\n",
    "\n",
    "\n",
    "##---------------Tokenizing and removing the Stopwords---------------##\n",
    "\n",
    "for words2 in word_tokenize(str2):\n",
    "    if words2 not in stop_words:\n",
    "        if words2.isalnum():\n",
    "            filtered_sentence2.append(words2)\n",
    "\n",
    "##---------------Lemmatizing: Root Words---------------##\n",
    "\n",
    "for i in filtered_sentence2:\n",
    "    lemm_sentence2.append(lemmatizer.lemmatize(i))\n",
    "    \n",
    "#print(lemm_sentence2)\n",
    "\n",
    "##---------------Removing the same words from the tokens----------------##\n",
    "##for word1 in lemm_sentence1:\n",
    "##    for word2 in lemm_sentence2:\n",
    "##        if word1 == word2:\n",
    "##            same_sent1.append(word1)\n",
    "##            same_sent2.append(word2)\n",
    "##            \n",
    "##if same_sent1 != []:\n",
    "##   for word1 in same_sent1:\n",
    "##    lemm_sentence1.remove(word1)\n",
    "##if same_sent2 != []:\n",
    "##   for word2 in same_sent2:\n",
    "##    lemm_sentence2.remove(word2)\n",
    "##            \n",
    "##print(lemm_sentence1)\n",
    "##print(lemm_sentence2)\n",
    "\n",
    "##---------------Similarity index calculation for each word---------------##\n",
    "for word1 in lemm_sentence1:\n",
    "    simi =[]\n",
    "    for word2 in lemm_sentence2:\n",
    "        sims = []\n",
    "       # print(word1)\n",
    "        #print(word2)\n",
    "        syns1 = wordnet.synsets(word1)\n",
    "        #print(syns1)\n",
    "        #print(wordFromList1[0])\n",
    "        syns2 = wordnet.synsets(word2)\n",
    "        #print(wordFromList2[0])\n",
    "        for sense1, sense2 in product(syns1, syns2):\n",
    "            d = wordnet.wup_similarity(sense1, sense2)\n",
    "            if d != None:\n",
    "                sims.append(d)\n",
    "    \n",
    "        #print(sims)\n",
    "        #print(max(sims))\n",
    "        if sims != []:        \n",
    "           max_sim = max(sims)\n",
    "           #print(max_sim)\n",
    "           simi.append(max_sim)\n",
    "             \n",
    "    if simi != []:\n",
    "        max_final = max(simi)\n",
    "        final.append(max_final)\n",
    "\n",
    "#print(final)\n",
    "\n",
    "#        if max_sim >= 0.7:\n",
    "#           print(word1)\n",
    "#           print(word2)\n",
    "#           print('\\n')\n",
    "           \n",
    "#           if word1 not in temp1:\n",
    "#              temp1.append(word1)\n",
    "#           if word2 not in temp2:\n",
    "#              temp2.append(word2)   \n",
    "           #lemm_sentence1.remove(word1)\n",
    "           #lemm_sentence2.remove(word2)          \n",
    "        #if wordFromList1 and wordFromList2: #Thanks to @alexis' note\n",
    "          #  s = wordFromList1[0].wup_similarity(wordFromList2[0])\n",
    "           # list.append(s)\n",
    "#for word1 in temp1:\n",
    "#    lemm_sentence1.remove(word1)\n",
    "\n",
    "#for word2 in temp2:\n",
    "#    lemm_sentence2.remove(word2)\n",
    "    \n",
    "#print(lemm_sentence1)\n",
    "#print(lemm_sentence2)\n",
    "\n",
    "\n",
    "##---------------Final Output---------------##\n",
    "\n",
    "similarity_index = numpy.mean(final)\n",
    "similarity_index = round(similarity_index , 2)\n",
    "print(\"Sentence 1: \",str1)\n",
    "print(\"Sentence 2: \",str2)\n",
    "print(\"Similarity index value : \", similarity_index)\n",
    "\n",
    "if similarity_index>0.8:\n",
    "    print(\"Similar\")\n",
    "elif similarity_index>=0.6:\n",
    "    print(\"Somewhat Similar\")\n",
    "else:\n",
    "    print(\"Not Similar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter first string: how old are you?\n",
      "Enter second string: what is your age?\n",
      "similarity:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Program to measure the similarity between  \n",
    "# two sentences using cosine similarity. \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "X = input(\"Enter first string: \").lower() \n",
    "Y = input(\"Enter second string: \").lower() \n",
    "#X =\"How old are you?\"\n",
    "#Y =\"what is your age?\"\n",
    "  \n",
    "# tokenization \n",
    "X_list = word_tokenize(X)  \n",
    "Y_list = word_tokenize(Y) \n",
    "  \n",
    "# sw contains the list of stopwords \n",
    "sw = stopwords.words('english')  \n",
    "l1 =[];l2 =[] \n",
    "  \n",
    "# remove stop words from the string \n",
    "X_set = {w for w in X_list if not w in sw}  \n",
    "Y_set = {w for w in Y_list if not w in sw} \n",
    "  \n",
    "# form a set containing keywords of both strings  \n",
    "rvector = X_set.union(Y_set)  \n",
    "for w in rvector: \n",
    "    if w in X_set: l1.append(1) # create a vector \n",
    "    else: l1.append(0) \n",
    "    if w in Y_set: l2.append(1) \n",
    "    else: l2.append(0) \n",
    "c = 0\n",
    "  \n",
    "# cosine formula  \n",
    "for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i] \n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "print(\"similarity: \", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
